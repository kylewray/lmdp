\section{Related Work}
\label{sec:related_work}

Recent work by~\citeauthor{Mouaddib04-MultiObjectivePathPlanning} used a strict lexicographic preference ordering for MOMDPs~\cite{Mouaddib04-MultiObjectivePathPlanning}. Their work formed the foundation on which we built our $\lvmax$ value iteration, which generalizes their work through the introduction of slack variables. Other work by~\citeauthor{Perny13-LorenzOptimalSolutionsMOMDPs} used Lorenz dominance with a weighted value functions favor more ``fair'' values~\cite{Perny13-LorenzOptimalSolutionsMOMDPs}.

In the past, others have used lexicographic ordering over value functions, calling this technique \emph{ordinal dynamic programming} \cite{Mitten74-PreferenceOrderDynamicProgramming,Sobel75-OrdinalDynamicProgramming}. Within the context of an MDP, \citeauthor{Mitten74-PreferenceOrderDynamicProgramming} assumed a specific preference ordering over outcomes in the finite horizon case. \citeauthor{Sobel75-OrdinalDynamicProgramming} extended this model to infinite horizon MDPs, but did not fully capture our $\lvmax$ formulation under value iteration, slack variables generalizes their approach, and we present experiments showing its efficacy in an applied setting. Ordinal dynamic programming has also been explored within the reinforcement learning community~\cite{Gabor98-MultiObjectiveReinforcementLearning,Natarajan05-DynamicPreferencesMultiCriteriaRL}, even with a similar notion of slack variables, but has not been represented in the general form we present.

\citeauthor{Barbara88-MaxminLeximax} characterized an operator called $\leximin$ within an economics context, which is closely related to $\lvmax$, except that the ordering is slightly different and does not include slack variables~\cite{Barbara88-MaxminLeximax}. Since its inception, it has enjoyed use outside the domain of MDPs by other economics researchers~\cite{Bossert94-RankingOpportunitySets,Fargier05-QuantitativeDecisionMaking,Arlegi05-FreedomOfChoice}.

Our algorithm can capture the strict avoidance of dead ends as well as loops. Interestingly,~\citeauthor{Kolobov12-TheoryGoalOrientedMDPsDeadEnds} showed that unavoidable dead ends can be represented by a ``price''~\cite{Kolobov12-TheoryGoalOrientedMDPsDeadEnds}. The resulting formulation resembles a specific, non-slack variable version of $\lvmax$ value iteration.

A solid survey of the approaches used to solve MOMDPs is provided by~\citeauthor{Roijers13-SurveyMultiObjective}~\shortcite{Roijers13-SurveyMultiObjective}, but other models exist. Constrained MDPs (CMDPs) are another formulation of MOMDPs, but to our knowledge no one has explored lexicographic preferences over rewards in this domain~\cite{Altman99-CMDPs}. Additionally,~\citeauthor{Gonzales11-DecisionMakingMultipleObjectivesGAINetworks} used Generalized Additive Decomposable (GAI) networks to capture the decomposability of the utility functions to model preferences~\cite{Gonzales11-DecisionMakingMultipleObjectivesGAINetworks}.
