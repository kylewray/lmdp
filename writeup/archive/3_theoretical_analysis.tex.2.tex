\section{Theoretical Analysis}
\label{sec:theoretical_analysis}

We provide a convergence proof for value iteration using $\lvmax$ in Proposition~\ref{prop:lvmax_vi_convergence}.

\begin{proposition}
    \label{prop:lvmax_vi_convergence}
    Lexicographic vector max ($\lvmax$) value iteration as defined by Equation~\ref{eq:lvmax_value_iteration} converges to within $\epsilon > 0$ of the optimal value function $\mathbf{V}^*(s)$, $\forall s \in S$, with termination criterion at time step $t$: $\|V^{t+1} - V^t\|_\infty < \epsilon (1 - \gamma) / \gamma$. FIX THIS STATEMENT
\end{proposition}

\begin{proof}
To prove convergence, we must show that the Bellman optimality equation converges to a unique fixed point. We will do this by induction on $i \in K$. First, we must state some definitions.

For a metric space $\langle X, d \rangle$, where $X$ is a set and $d$ is a distance metric, a map $f : X \rightarrow X$ is called a \emph{contraction map} if there exists an $\alpha$ such that $d(f(x), f(y)) = \alpha d(x, y)$, for all $x, y \in X$.

Let the space $X_i$ be the \emph{space of value functions for $i \in K$}, i.e., we have $V_i = [V_i(s_1), \ldots, V_i(s_n)]^T \in X_i$. Let the distance metric $d_i$ be the \emph{max norm}, i.e., $\|V_i\|_\infty = \max_{s \in S} |V_i(s)|$. Since $\gamma_i \in [0, 1)$, the metric space $M_i = \langle X_i, d_i \rangle$ is a \emph{complete metric space}; every Cauchy sequence of $M_i$ converges to a point in $M_i$.

Let the $\lvmax$ Bellman optimality equation's (Equation~\ref{eq:lvmax_value_iteration}) be defined as an operator $B$, i.e., $V^{t+1} = B V^t$, for $V^t, V^{t+1} \in X$ with $t \geq 0$. Let element $i \in K$ of the operator be $B_i$, such that $V_i^{t+1} = (B V^t)_i = B_i V_i^t$. We prove the operator $B_i$ is a contraction map in $M_i$ for all $i \in K$, given either that $i=1$ or that the previous $i-1$ has converged to within $\epsilon$ of its fixed point.

Let $V_{1i}, V_{2i} \in X_i$ be any two value function vectors, and $\gamma_i \in [0, 1)$. We first apply the definition of $\lvmax$ from Equation~\ref{eq:lvmax}.
\begin{equation*}
    \| B_i V_{1i} - B_i V_{2i} \|_\infty = \max_{s \in S} | \max_{a \in A_{1i}^*} Q_{1i}(s, a) - \max_{a \in A_{2i}^*} Q_{2i}(s, a) |
\end{equation*}
By Definition~\ref{def:lvmax}, $A_{1i}^* \subseteq A_{1i}$. Therefore, for all $s \in S$, $\max_{a \in A_{1i}^*} Q_{1i}(s, a) \leq \max_{a' \in A_{1i}} Q_{1i}(s, a)$. Also by Definition~\ref{def:lvmax}, for all $a^* \in A_{2i}^* \subseteq A_{2,i+1} = \{a \in A_{2i} | \max_{a' \in A_{2i}} Q_{2i}(s, a') - Q_{2i}(s, a) \leq \delta_i \}$. Thus,
\begin{multline*}
    \max_{a' \in A_{2i}} Q_{2i}(s, a') - \delta_i \leq Q_{2i}(s, a^*) \leq \max_{a' \in A_{2i}^*} Q_{2i} (s, a') \\
    -\max_{a' \in A_{2i}} Q_{2i} (s, a') \leq \delta_i - \max_{a' \in A_{2i}} Q_{2i}(s, a')
\end{multline*}
Combine these two facts, and we obtain the following.
\begin{multline*}
    \| B_i V_{1i} - B_i V_{2i} \|_\infty \\
    \leq \max_{s \in S} | \max_{a \in A_{1i}} Q_{1i}(s, a) - \max_{a \in A_{2i}} Q_{2i}(s, a) + \delta_i | \\
    \leq \max_{s \in S} | \max_{a \in A_{1i}} Q_{1i}(s, a) - \max_{a \in A_{2i}} Q_{2i}(s, a)| + |\delta_i|
\end{multline*}

By Definition~\ref{def:lvmax}, when $i=1$ we have $A_{1i} = A_{2i} = A$. Similarly, when $i \in \{2, \ldots, k\}$ given that $i-1$ has converged to within $\epsilon$ of its fixed point, it yields a unique fixed set of actions $A'$, with $A_{1i} = A_{2i} = A' \subseteq A$. Let us denote this fixed actions set as $\bar{A}_i$ for all $i \in K$. Also, as part of the $Q(\cdot)$ values, we distribute $T(\cdot)$ to each $R(\cdot)$ and $V(\cdot)$ in the summations, then apply the property: $\max_x f(x) + g(x) \leq \max_x f(x) + \max_x g(x)$, twice.
\begin{multline*}
    \| B_i V_{1i} - B_i V_{2i} \|_\infty \\
    \leq \max_{s \in S} \Big| \max_{a \in \bar{A}_i} \Big( \sum_{s' \in S} T(s, a, s') R_i(s, a, s') \\
    + \gamma_i \sum_{s' \in S} T(s, a, s') V_{1i}(s') \Big) \\
    - \max_{a \in \bar{A}_i} \Big( \sum_{s' \in S} T(s, a, s') R_i(s, a, s') \\
    - \gamma_i \sum_{s' \in S} T(s, a, s') V_{2i}(s') \Big) \Big| + \delta_i \\
    \leq \max_{s \in S} \Big| \max_{a \in \bar{A}_i} \sum_{s' \in S} T(s, a, s') R_i(s, a, s') \\
    + \gamma_i \max_{a \in \bar{A}_i} \sum_{s' \in S} T(s, a, s') V_{1i}(s') \\
    - \max_{a \in \bar{A}_i} \sum_{s' \in S} T(s, a, s') R_i(s, a, s') \\
    - \gamma_i \max_{a \in \bar{A}_i} \sum_{s' \in S} T(s, a, s') V_{2i}(s') \Big| + \delta_i \\
    \leq \max_{s \in S} \Big| \gamma_i \max_{a \in \bar{A}_i} \sum_{s' \in S} T(s, a, s') V_{1i}(s') \\
    - \gamma_i \max_{a \in \bar{A}_i} \sum_{s' \in S} T(s, a, s') V_{2i}(s') \Big| + \delta_i
\end{multline*}
Note that we can pull out $\gamma_i \in [0, 1)$. Recall, that for any two functions $f$ and $g$, $| \max_x f(x) - \max_x g(x) | \leq \max_x | f(x) - g(x) |$.
\begin{multline*}
    \| B_i V_{1i} - B_i V_{2i} \|_\infty \\
    \leq \gamma_i \max_{s \in S} \max_{a \in \bar{A}_i} \Big| \sum_{s' \in S} T(s, a, s') (V_{1i}(s') - V_{2i}(s')) \Big| + \delta_i
\end{multline*}

Since $\sum_{s' \in S} T(s, a, s') = 1$ and for all $s' \in S$, $T(s, a, s') \in [0, 1]$, it is defined on the $n$-simplex. It then scales the vertices by the values $R(\cdot)$ or $V(\cdot)$. This forms simple convex polytope. Convex polytopes obtain their maximum value at the vertices (or on an entire edge or face, which includes the vertices). Therefore, we may exclusively maximize over these vertices ($R(\cdot)$ and $V(\cdot)$), and may simply drop both maximizations which select the weights (i.e., maximization over $s \in S$ and $a \in A$).
\begin{multline*}
    \| B_i V_{1i} - B_i V_{2i} \|_\infty \leq \gamma_i \max_{s' \in S} \Big| V_{1i}(s') - V_{2i}(s') \Big| + \delta_i \\
        \leq \gamma_i \| V_{1i} - V_{2i} \|_\infty + \delta_i \\
        \leq \gamma_i \| V_{1i} - V_{2i} \|_\infty + \delta_i \frac{\| V_{1i} - V_{2i} \|_\infty}{\| V_{1i} - V_{2i} \|_\infty} \\
        \leq \Big( \gamma_i + \frac{\delta_i}{\| V_{1i} - V_{2i} \|_\infty} \Big) \| V_{1i} - V_{2i} \|_\infty
\end{multline*}

We can place a constant upper bound on this value to remove the denominator $\| V_{1i} - V_{2i} \|_\infty$. Consider any finite or finite sequence of states and actions performed by the agent: $z = \langle s^0, a^0, s^1, a^1, \ldots \rangle$. The utility $u_i^h(z)$ at horizon $h \in \mathbb{N} \cup \{ \infty \}$ is bounded:
\begin{multline*}
    u_i^h(\langle s^0, a^0, s^1, a^1, \ldots \rangle) = \sum_{t=0}^h \gamma_i^t R_i(s^t, a^t, s^{t+1}) \\
    \leq \sum_{t=0}^\infty \gamma_i^t R_{i,max} \leq \frac{R_{i,max}}{1 - \gamma_i}
\end{multline*}
with $R_{i,max} = \max_{s \in S} \max_{a \in A} \max_{s' \in S} R_i(s, a, s')$. The value function is therefore bounded by this value, because state transitions would only decrease this value.
\begin{equation*}
    \| V_{1i} - V_{2i} \|_\infty \leq \frac{R_{i,max}}{1 - \gamma_i} - \frac{-R_{i,max}}{1 - \gamma_i} \leq \frac{2 R_{i,max}}{1 - \gamma_i}
\end{equation*}

Now we may obtain final result, proving that the Bellman operator $B_i$ is a contraction map on metric space $M_i$, for all $i \in K$.
\begin{multline*}
    \| B_i V_{1i} - B_i V_{2i} \|_\infty \leq \Big( \gamma_i + \frac{\delta_i}{???} \Big) \| V_{1i} - V_{2i} \|_\infty \\
    \leq \Big( \gamma_i + \frac{\delta_i}{???} \Big) \| V_{1i} - V_{2i} \|_\infty \\
    \| B_i V_{1i} - B_i V_{2i} \|_\infty \leq \gamma_i \| V_{1i} - V_{2i} \|_\infty
\end{multline*}

By definition of a contraction map, $B_i$ admits at most one fixed point. Additionally, since $M_i$ is a complete metric space, we can guarantee convergence to a unique fixed point. \emph{Banach's fixed point theorem} states that if $M_i = \langle X_i, d_i \rangle$ is a complete metric space and $B_i: X_i \rightarrow X_i$ is a contraction map, then $B_i$ admits a unique fixed point $V_i^* \in X_i$, i.e., $B_i V_i^* = V_i^*$. Thus, we will have convergence of value iteration to a unique fixed point $V_i^* \in X_i$.

Finally, a corollary of Banach's fixed point theorem is that the speed of convergence to within $\epsilon > 0$ of the fixed point $x^*$ is known (using the generic notation from above for a metric space).
\begin{multline*}
    d(x^*, x_{t+1}) \leq \frac{\alpha}{1 - \alpha} d(x_{t+1}, x_t) \\
    \| V_i^* - V_i^{t+1}\|_\infty \leq \frac{\gamma_i}{1 - \gamma_i} \| V_i^{t+1} - V_i^t \|_\infty
\end{multline*}
% It is an interesting side fact that $\gamma_i$ is the \emph{Lipschitz constant} for the Bellman operator $B$. This contraction map property comes from Banach's fixed point theorem.

Since we want the distance from the fixed point $V_i^* \in X_i$ to be $\epsilon$, we may rewrite the equation accordingly.
\begin{multline*}
    \epsilon \leq \frac{\gamma_i}{1 - \gamma_i} \| V_i^{t+1} - V_i^t \|_\infty \\
    \epsilon \frac{1 - \gamma_i}{\gamma_i} \leq \| V_i^{t+1} - V_i^t \|_\infty
\end{multline*}
The above equation states that we are at least $\epsilon$ (or more) away from the fixed point when the maximum difference (over the states) between iterations satisfies the inequality. Therefore, we flip the inequality to create a convergence criterion, which ensures that we are $\epsilon$ or less from the fixed point.
\begin{equation*}
    \quad \| V_i^{t+1} - V_i^t \|_\infty < \epsilon \frac{1 - \gamma_i}{\gamma_i}
\end{equation*}

In summary, we know that the iteration of Bellman's optimality equation converges to a unique fixed point in the space of value function vectors, and we know how to check for convergence to within $\epsilon > 0$ of the fixed point.
\end{proof}

Typically, a multi-objective optimization problem converts the problem into a objective function by summing the various objectives and weighting them in a particular manner. The possible policies returned by our $\lvmax$ value iteration is unique from the canonical weighted function approaches used to solve MOMDPs. Proposition~\ref{prop:lvmax_vi_uniqueness} proves this fact.

Let the set of all policies returned by value iteration operator $B$ be denoted as $\Pi_B$. Formally, we say that the value iteration operator $B$ is \emph{unique} with respect to value iteration operator $B'$, if and only for some $\epsilon > 0$ and $\gamma_i \in [0, 1)$ in MDP $M = \langle S, A, T, R \rangle$, $\Pi_B \not\subseteq \Pi_{B'}$ and $\Pi_{B'} \not\subseteq \Pi_B$.

\begin{proposition}
    \label{prop:lvmax_vi_uniqueness}
    For $\epsilon > 0$ and $\gamma \in [0, 1)$, let $\Pi_{vi}$ be the set of all policies returned by value iteration operator $B_{vi}$ using a weighted objective function with weights $\mathbf{w} \in \mathbb{R}^k$. Also, let $\Pi_{lv}$ be the set of all policies returned by value iteration operator $B_{lv}$ as defined by Equation~\ref{eq:lvmax_value_iteration} with $\epsilon$ and $\gamma$. $B_{lv}$ is unique with respect to $B_{vi}$.
\end{proposition}

\begin{proof}
By the definition of uniqueness, must show that there exists an MDP $M = \langle S, A, T, R \rangle$ such that $\Pi_{vi} \not\subseteq \Pi_{lv}$ and $\Pi_{lv} \not\subseteq \Pi_{vi}$. Assume by contradiction that $\forall M$, $\Pi_{vi} \subseteq \Pi_{lv}$ or $\Pi_{lv} \subset \Pi_{vi}$.

\end{proof}
